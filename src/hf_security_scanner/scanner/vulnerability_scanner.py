"""
Vulnerability Scanner - Scans for known vulnerabilities in dependencies.
"""

from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import re

from ..utils.logger import get_logger
from ..utils.security_utils import create_security_issue
from ..data import VULNERABLE_PACKAGES, UNSAFE_LOADING_PATTERNS

logger = get_logger(__name__)


@dataclass
class VulnerabilityAnalysisResult:
    """Result of vulnerability analysis."""
    vulnerabilities_found: List[Dict[str, Any]]
    security_issues: List[Dict[str, Any]]
    risk_score: float


class VulnerabilityScanner:
    """Scans for known vulnerabilities and unsafe patterns."""
    
    def __init__(self):
        """Initialize the vulnerability scanner."""
        self.vulnerable_packages = VULNERABLE_PACKAGES
        self.unsafe_patterns = UNSAFE_LOADING_PATTERNS
        logger.debug("VulnerabilityScanner initialized")
    
    def scan_vulnerabilities(
        self,
        model_metadata: Dict[str, Any],
        files: List[str]
    ) -> VulnerabilityAnalysisResult:
        """
        Scan for vulnerabilities in model.
        
        Args:
            model_metadata: Model metadata dictionary
            files: List of files in repository
            
        Returns:
            VulnerabilityAnalysisResult with findings
        """
        logger.info("Scanning for vulnerabilities")
        
        vulnerabilities = []
        security_issues = []
        
        # Check for requirements.txt or similar dependency files
        dep_files = [f for f in files if self._is_dependency_file(f)]
        
        if dep_files:
            logger.debug(f"Found {len(dep_files)} dependency files")
            for dep_file in dep_files:
                issues = self._analyze_dependency_file(dep_file)
                security_issues.extend(issues)
        
        # Check for unsafe loading patterns in code files
        code_files = [f for f in files if f.endswith(('.py', '.ipynb'))]
        if code_files:
            loading_issues = self._check_unsafe_loading_patterns(code_files)
            security_issues.extend(loading_issues)
        
        # Check library version from metadata
        library_name = model_metadata.get('library_name')
        if library_name:
            lib_issues = self._check_library_vulnerabilities(library_name)
            security_issues.extend(lib_issues)
            vulnerabilities.extend(lib_issues)
        
        risk_score = self._calculate_vulnerability_risk_score(security_issues)
        
        result = VulnerabilityAnalysisResult(
            vulnerabilities_found=vulnerabilities,
            security_issues=security_issues,
            risk_score=risk_score
        )
        
        logger.info(f"Vulnerability scan complete: {len(vulnerabilities)} vulnerabilities, "
                   f"risk score: {risk_score}")
        
        return result
    
    def _is_dependency_file(self, filename: str) -> bool:
        """Check if file is a dependency specification file."""
        dep_files = [
            'requirements.txt',
            'environment.yml',
            'environment.yaml',
            'Pipfile',
            'pyproject.toml',
            'setup.py',
            'package.json'
        ]
        return any(filename.endswith(dep) for dep in dep_files)
    
    def _analyze_dependency_file(self, dep_file: str) -> List[Dict[str, Any]]:
        """
        Analyze a dependency file for vulnerable packages.
        
        Note: In a real implementation, we would download and parse the file.
        For now, we just flag that dependencies should be checked.
        """
        issues = []
        
        issues.append(create_security_issue(
            severity="low",
            category="vulnerability",
            title="Dependency file found",
            description=f"Found dependency file: {dep_file}",
            recommendation="Review dependencies for known vulnerabilities",
            details={"file": dep_file}
        ))
        
        return issues
    
    def _check_unsafe_loading_patterns(self, code_files: List[str]) -> List[Dict[str, Any]]:
        """
        Check for unsafe model loading patterns in code files.
        
        Args:
            code_files: List of Python/notebook files
            
        Returns:
            List of security issues
        """
        issues = []
        
        # Flag if there are Python files (could contain unsafe loading)
        if code_files:
            issues.append(create_security_issue(
                severity="medium",
                category="vulnerability",
                title="Code files detected",
                description=f"Found {len(code_files)} code file(s) that may contain unsafe loading patterns",
                recommendation="Review code for torch.load, pickle.load, or other unsafe deserialization",
                details={"files": code_files[:5]}
            ))
        
        return issues
    
    def _check_library_vulnerabilities(self, library_name: str) -> List[Dict[str, Any]]:
        """
        Check if the library has known vulnerabilities.
        
        Args:
            library_name: Name of the ML library (e.g., 'transformers', 'pytorch')
            
        Returns:
            List of security issues
        """
        issues = []
        
        # Check against known vulnerable packages
        if library_name in self.vulnerable_packages:
            issues.append(create_security_issue(
                severity="info",
                category="vulnerability",
                title=f"Library {library_name} flagged",
                description=f"Model uses {library_name} which has had security advisories",
                recommendation="Verify you're using a patched version of the library"
            ))
        
        return issues
    
    def _calculate_vulnerability_risk_score(self, security_issues: List[Dict[str, Any]]) -> float:
        """Calculate risk score from vulnerability issues."""
        score = 0.0
        
        severity_weights = {
            "critical": 5.0,
            "high": 3.0,
            "medium": 1.5,
            "low": 0.5,
            "info": 0.1
        }
        
        for issue in security_issues:
            severity = issue.get("severity", "low")
            score += severity_weights.get(severity, 0.5)
        
        return min(10.0, round(score, 2))
